{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6a4b96a46748>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Census API Key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCensus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2018\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from census import Census\n",
    "from us import states\n",
    "\n",
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Census API Key\n",
    "from config import api_key,gkey\n",
    "c = Census(api_key, year=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Census Search to retrieve data on all zip codes (2013 ACS5 Census)\n",
    "# See: https://github.com/CommerceDataService/census-wrapper for library documentation\n",
    "# See: https://gist.github.com/afhaque/60558290d6efd892351c4b64e5c01e9b for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # retrieve the census data using the for / in in the Fips format\n",
    "    mdcheck = c.acs5.get((\"NAME\", \"B19013_001E\", \"B01003_001E\", \"B01002_001E\",\n",
    "                          \"B19301_001E\",\n",
    "                          \"B17001_002E\"),\n",
    "           geo={'for': 'zip code tabulation area:*',\n",
    "                        'in': 'state:{}'.format(states.IN.fips)})\n",
    "\n",
    " # Convert to DataFrame\n",
    "census_pd2 = pd.DataFrame(mdcheck)\n",
    "\n",
    "census_pd2.head()\n",
    " len(census_pd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in Poverty Rate (Poverty Count / Population)\n",
    "census_pd2[\"Poverty Rate\"] = 100 * \\\n",
    "    census_pd2[\"B17001_002E\"].astype(\n",
    "        int) / census_pd2[\"B01003_001E\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_pd2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Reordering\n",
    "census_pd2 = census_pd2.rename(columns={\"B01003_001E\": \"Population\",\n",
    "                                      \"B01002_001E\": \"Median Age\",\n",
    "                                      \"B19013_001E\": \"Household Income\",\n",
    "                                      \"B19301_001E\": \"Per Capita Income\",\n",
    "                                      \"B17001_002E\": \"Poverty Count\",\n",
    "                                      \"NAME\": \"Name\", \"zip code tabulation area\": \"Zipcode\"})\n",
    "# Final DataFrame\n",
    "census_pd_final = census_pd2[[\"Zipcode\", \"Population\", \"Median Age\", \"Household Income\",\n",
    "                       \"Per Capita Income\", \"Poverty Count\", \"Poverty Rate\"]]\n",
    "\n",
    "# Visualize\n",
    "print(len(census_pd_final))\n",
    "census_pd_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a csv\n",
    "# Note to avoid any issues later, use encoding=\"utf-8\"\n",
    "census_pd_final.to_csv(\"census_data_indiana_2014.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame df for university data\n",
    "uni_df_raw = pd.read_csv('universities.csv', index_col=0)\n",
    "\n",
    "# Show dataframe\n",
    "uni_df_raw.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-read CSV file into DataFrame df for purposes of grabbing city only (this is inefficient, but it's already built, sooo)\n",
    "df = pd.read_csv('universities.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with just the city name\n",
    "city_list = df[[\"City\"]]\n",
    "city_list\n",
    "\n",
    "# Remove any duplicates before feeding it through the API\n",
    "city_list_dedup = city_list.drop_duplicates()\n",
    "city_list_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list_dedup['Lat']=\" \"\n",
    "city_list_dedup['Lng']=\" \"\n",
    "\n",
    "city_list_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a request to endpoint and convert result to json\n",
    "\n",
    "lonely_city = []\n",
    "\n",
    "\n",
    "for index,row in city_list_dedup.iterrows():\n",
    "    \n",
    "    target_city_row = row[\"City\"]\n",
    "    \n",
    "    target_city = f\"{target_city_row}, Indiana\"\n",
    "\n",
    "# Build the endpoint URL\n",
    "    target_url = ('https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "    'address={0}&key={1}').format(target_city, gkey)\n",
    "    \n",
    "    geo_data = requests.get(target_url).json()\n",
    "    \n",
    "# Extract latitude and longitude\n",
    "    try:\n",
    "        city_list_dedup.loc[index,\"Lat\"] = geo_data[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "        city_list_dedup.loc[index,\"Lng\"] = geo_data[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
    "        print(f\"Record found at {target_city}\")\n",
    "    except (KeyError, IndexError):\n",
    "        print(f\"Record could not be found at {target_city}\")\n",
    "        lonely_city = target_city_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Index to City to complete the merge with uni_df\n",
    "city_list_dedup2 = city_list_dedup.set_index('City')\n",
    "city_list_dedup2\n",
    "\n",
    "#complete the merge\n",
    "merged_df = uni_df_raw.join(city_list_dedup2, on='City')\n",
    "merged_df2 = merged_df.reset_index()\n",
    "\n",
    "# Note to avoid any issues later, use encoding=\"utf-8\"\n",
    "merged_df2.to_csv(\"city_lat_long_ind.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "\n",
    "merged_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in merged_df2.iterrows():\n",
    "    \n",
    "    target_lat = row[\"Lat\"]\n",
    "    target_lng = row[\"Lng\"]\n",
    "    target_school = row[\"School\"]\n",
    "\n",
    "    # geocoordinates\n",
    "    target_coordinates = f\"{target_lat}, {target_lng}\"\n",
    "    target_search = f\"{target_school}\"\n",
    "    target_radius = 10000\n",
    "\n",
    "    # set up a parameters dictionary\n",
    "    params = {\n",
    "        \"location\": target_coordinates,\n",
    "        \"keyword\": target_search,\n",
    "        \"radius\": target_radius,\n",
    "        \"key\": gkey\n",
    "    }\n",
    "\n",
    "    # base url\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "\n",
    "    # run a request using our params dictionary\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    places_data = response.json()\n",
    "    \n",
    "    # Extract place_id which will be used to find ZIP Code\n",
    "    try:\n",
    "        merged_df2.loc[index,\"place_id\"] = places_data[\"results\"][0][\"place_id\"]\n",
    "        print(f\"Record found at {target_school}\")\n",
    "    except (KeyError, IndexError):\n",
    "        print(f\"Record could not be found at {target_school} at {target_lat} and {target_lng}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Davenport college as further research shows it's in Michigan and and online only\n",
    "clean_merge = merged_df2[merged_df2['School']!=\"DAVENPORT COLLEGE\"]\n",
    "clean_merge.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in clean_merge.iterrows():\n",
    "    \n",
    "    target_place_id = row[\"place_id\"]\n",
    "    \n",
    "\n",
    "# Build the endpoint URL\n",
    "    target_url = (f'https://maps.googleapis.com/maps/api/place/details/json?place_id={target_place_id}&key={gkey}')\n",
    "    \n",
    "    zip_data = requests.get(target_url).json()\n",
    "    \n",
    "# Extract latitude and longitude\n",
    "    try:\n",
    "        if zip_data[\"result\"][\"address_components\"][7][\"long_name\"] == \"United States\":\n",
    "            clean_merge.loc[index,\"Zip Code\"] = zip_data[\"result\"][\"address_components\"][8][\"long_name\"]\n",
    "        else:\n",
    "            clean_merge.loc[index,\"Zip Code\"] = zip_data[\"result\"][\"address_components\"][7][\"long_name\"]\n",
    "        print(f\"Record found at {target_place_id}\")\n",
    "    except (KeyError, IndexError):\n",
    "#         if IndexError:\n",
    "#             lat_long_df2.loc[index,\"Zip Code\"] = zip_data[\"result\"][\"address_components\"][6][\"long_name\"]\n",
    "#             print(f\"Record found with 6 index for {target_place_id}\")\n",
    "#         else:\n",
    "        print(f\"Record could not be found for{target_place_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reviewing record not found issues\n",
    "missing_zips = clean_merge[(clean_merge['place_id']==\"ChIJa8kQbDA_EogRaj5xfkug230\")|(clean_merge['place_id']==\"ChIJUe6QWPnLFogRinKUEbLx5oY\")]\n",
    "missing_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick research shows that these 2 items have a different api dictionary range than the others, will fix with a separate call\n",
    "for index,row in missing_zips.iterrows():\n",
    "    \n",
    "    target_place_id = row[\"place_id\"]\n",
    "    \n",
    "\n",
    "# Build the endpoint URL\n",
    "    target_url = (f'https://maps.googleapis.com/maps/api/place/details/json?place_id={target_place_id}&key={gkey}')\n",
    "    \n",
    "    zip_data = requests.get(target_url).json()\n",
    "    \n",
    "# Extract ZIP code using the secondary retry logic and placing it back into the clean_merge with the same index values\n",
    "    try:\n",
    "        if zip_data[\"result\"][\"address_components\"][5][\"long_name\"] == \"United States\":\n",
    "            clean_merge.loc[index,\"Zip Code\"] = zip_data[\"result\"][\"address_components\"][6][\"long_name\"]\n",
    "        else:\n",
    "            clean_merge.loc[index,\"Zip Code\"] = zip_data[\"result\"][\"address_components\"][5][\"long_name\"]\n",
    "    except (KeyError, IndexError):\n",
    "        print(f\"Record could not be found for{target_place_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final clean merge with a zip code for each school\n",
    "clean_merge\n",
    "\n",
    "clean_merge.to_csv(\"colleges_unis_with_zips.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#start to get the normalized data\n",
    "schools_by_zip = clean_merge[\"Zip Code\"].value_counts()\n",
    "schools_by_zip_df = pd.DataFrame(schools_by_zip)\n",
    "\n",
    "#schools summarized by zip\n",
    "schools_by_zip_df.tocsv('normalized_uni_zip_data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
